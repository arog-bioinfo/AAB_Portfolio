{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Metabólicas\n",
    "\n",
    "##  Projeto de Alto Nível\n",
    "\n",
    "### Componentes Principais\n",
    "\n",
    "1. **Entrada de Dados (`ecoli.txt`)**\n",
    "   - Formato: uma reação por linha\n",
    "   - Exemplo: `R1: A + B => C + D`\n",
    "\n",
    "2. **Parser de Reações**\n",
    "   - Extrai dados estruturados de substratos e produtos\n",
    "   - Produz uma lista de dicionários:\n",
    "     ```python\n",
    "     {\n",
    "       \"id\": \"R1\",\n",
    "       \"substrates\": [\"A\", \"B\"],\n",
    "       \"products\": [\"C\", \"D\"]\n",
    "     }\n",
    "     ```\n",
    "\n",
    "3. **Construção do Grafo Metabólico**\n",
    "   - Usa a classe `MyGraph`\n",
    "   - Cada nó representa um metabolito\n",
    "   - Arestas ligam metabolitos que participam da mesma reação\n",
    "\n",
    "4. **Módulo de Centralidade (`CentralityAnalyzer`)**\n",
    "   - Calcula:\n",
    "     - Centralidade de grau (Degree)\n",
    "     - Centralidade de proximidade (Closeness)\n",
    "     - Centralidade de intermediação (Betweenness)\n",
    "\n",
    "5. **Módulo de Propagação de Metabolitos**\n",
    "   - Dado um conjunto inicial de metabolitos:\n",
    "     - Identifica reações ativas (todos os substratos disponíveis)\n",
    "     - Coleta produtos gerados\n",
    "     - Repete o processo iterativamente\n",
    "\n",
    "6. **Saída**\n",
    "   - Lista dos metabolitos mais centrais por métrica\n",
    "   - Metabolitos finais produzíveis a partir de um conjunto inicial\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto de Baixo Nível\n",
    "\n",
    "### Funções Principais\n",
    "\n",
    "####  `parse_reactions(filepath)`\n",
    "- Lê `ecoli.txt` e transforma em dicionários de reação\n",
    "\n",
    "####  `build_metabolite_graph(reactions)`\n",
    "- Constrói um grafo a partir da coocorrência de metabolitos\n",
    "\n",
    "####  `CentralityAnalyzer`\n",
    "- Classe para cálculo das centralidades\n",
    "- Métodos:\n",
    "  - `degree_centrality()`\n",
    "  - `closeness_centrality()`\n",
    "  - `betweenness_centrality()`\n",
    "  - `top_nodes(centrality_dict, top_n)`\n",
    "\n",
    "####  `get_active_reactions(metabolites, reactions)`\n",
    "- Retorna reações cujos substratos estão disponíveis\n",
    "\n",
    "####  `get_produced_metabolites(active_reactions)`\n",
    "- Retorna os produtos das reações ativas\n",
    "\n",
    "####  `compute_final_metabolites(initial_metabs, reactions)`\n",
    "- Aplica a propagação metabólica iterativamente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import heapq\n",
    "\n",
    "class CentralityAnalyzer:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "\n",
    "    def degree_centrality(self):\n",
    "        return {node: len(self.graph.get_successors(node)) for node in self.graph.get_nodes()}\n",
    "\n",
    "    def closeness_centrality(self):\n",
    "        centrality = {}\n",
    "        for node in self.graph.get_nodes():\n",
    "            total_dist = self._bfs_total_distance(node)\n",
    "            centrality[node] = (len(self.graph.get_nodes()) - 1) / total_dist if total_dist > 0 else 0\n",
    "        return centrality\n",
    "\n",
    "    def _bfs_total_distance(self, start):\n",
    "        visited = set()\n",
    "        queue = deque([(start, 0)])\n",
    "        total = 0\n",
    "        while queue:\n",
    "            node, dist = queue.popleft()\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                total += dist\n",
    "                for neighbor in self.graph.get_successors(node):\n",
    "                    if neighbor not in visited:\n",
    "                        queue.append((neighbor, dist + 1))\n",
    "        return total\n",
    "\n",
    "    def betweenness_centrality(self):\n",
    "        centrality = dict.fromkeys(self.graph.get_nodes(), 0.0)\n",
    "        for s in self.graph.get_nodes():\n",
    "            stack = []\n",
    "            pred = {w: [] for w in self.graph.get_nodes()}\n",
    "            sigma = dict.fromkeys(self.graph.get_nodes(), 0)\n",
    "            dist = dict.fromkeys(self.graph.get_nodes(), -1)\n",
    "            sigma[s] = 1\n",
    "            dist[s] = 0\n",
    "            queue = deque([s])\n",
    "\n",
    "            while queue:\n",
    "                v = queue.popleft()\n",
    "                stack.append(v)\n",
    "                for w in self.graph.get_successors(v):\n",
    "                    if dist[w] < 0:\n",
    "                        dist[w] = dist[v] + 1\n",
    "                        queue.append(w)\n",
    "                    if dist[w] == dist[v] + 1:\n",
    "                        sigma[w] += sigma[v]\n",
    "                        pred[w].append(v)\n",
    "\n",
    "            delta = dict.fromkeys(self.graph.get_nodes(), 0)\n",
    "            while stack:\n",
    "                w = stack.pop()\n",
    "                for v in pred[w]:\n",
    "                    delta[v] += (sigma[v] / sigma[w]) * (1 + delta[w])\n",
    "                if w != s:\n",
    "                    centrality[w] += delta[w]\n",
    "        return centrality\n",
    "\n",
    "    def top_nodes(self, centrality_dict, top_n=5):\n",
    "        return heapq.nlargest(top_n, centrality_dict.items(), key=lambda x: x[1])\n",
    "\n",
    "# REACTION PARSER\n",
    "def parse_reactions(file_path):\n",
    "    \"\"\"Parses ecoli.txt into a list of reaction dicts\"\"\"\n",
    "    reactions = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if ':' not in line: continue\n",
    "            parts = re.split(r':\\s*', line.strip(), maxsplit=1)\n",
    "            if len(parts) != 2: continue\n",
    "            reaction_id, formula = parts\n",
    "            match = re.search(r\"(.*)\\s*(=>|<=>)\\s*(.*)\", formula)\n",
    "            if not match: continue\n",
    "            substrates = [m.strip() for m in match.group(1).split('+')]\n",
    "            products = [m.strip() for m in match.group(3).split('+')]\n",
    "            reactions.append({\n",
    "                'id': reaction_id,\n",
    "                'substrates': substrates,\n",
    "                'products': products\n",
    "            })\n",
    "    return reactions\n",
    "\n",
    "def build_metabolite_graph(reactions):\n",
    "    g = MyGraph()\n",
    "    for r in reactions:\n",
    "        metabolites = r['substrates'] + r['products']\n",
    "        for i in range(len(metabolites)):\n",
    "            for j in range(i + 1, len(metabolites)):\n",
    "                g.add_edge(metabolites[i], metabolites[j])\n",
    "    return g\n",
    "\n",
    "# ASSESSMENT FUNCTIONS\n",
    "def get_active_reactions(metabolites_set, reactions):\n",
    "    return [r for r in reactions if all(sub in metabolites_set for sub in r['substrates'])]\n",
    "\n",
    "def get_produced_metabolites(active_reactions):\n",
    "    produced = set()\n",
    "    for r in active_reactions:\n",
    "        produced.update(r['products'])\n",
    "    return produced\n",
    "\n",
    "def compute_final_metabolites(initial_metabolites, reactions):\n",
    "    known_metabolites = set(initial_metabolites)\n",
    "    while True:\n",
    "        active = get_active_reactions(known_metabolites, reactions)\n",
    "        new = get_produced_metabolites(active)\n",
    "        if new.issubset(known_metabolites):\n",
    "            break\n",
    "        known_metabolites.update(new)\n",
    "    return known_metabolites\n",
    "\n",
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"ecoli.txt\"\n",
    "    reactions = parse_reactions(file_path)\n",
    "    \n",
    "    print(\" Reactions parsed:\", len(reactions))\n",
    "\n",
    "    # Centrality Analysis\n",
    "    g = build_metabolite_graph(reactions)\n",
    "    analyzer = CentralityAnalyzer(g)\n",
    "\n",
    "    print(\"\\n--- Degree Centrality ---\")\n",
    "    for node, val in analyzer.top_nodes(analyzer.degree_centrality()):\n",
    "        print(f\"{node}: {val}\")\n",
    "\n",
    "    print(\"\\n--- Closeness Centrality ---\")\n",
    "    for node, val in analyzer.top_nodes(analyzer.closeness_centrality()):\n",
    "        print(f\"{node}: {val:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Betweenness Centrality ---\")\n",
    "    for node, val in analyzer.top_nodes(analyzer.betweenness_centrality()):\n",
    "        print(f\"{node}: {val:.4f}\")\n",
    "\n",
    "    #  Metabolite Propagation \n",
    "    initial_metabs = [\"M_glc_DASH_D_c\", \"M_h2o_c\", \"M_nad_c\", \"M_atp_c\"]\n",
    "    final_metabs = compute_final_metabolites(initial_metabs, reactions)\n",
    "\n",
    "    print(\"\\n--- Initial Metabolites ---\")\n",
    "    print(initial_metabs)\n",
    "\n",
    "    print(\"\\n--- Final Reachable Metabolites ---\")\n",
    "    print(sorted(final_metabs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4d4a9e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f502e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import regex as re\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986b7d7",
   "metadata": {},
   "source": [
    "## Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b188d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, g=None):\n",
    "        self.graph = {}\n",
    "        if g:\n",
    "            for v, neighbors in g.items():\n",
    "                self.add_vertex(v)\n",
    "                for d in neighbors:\n",
    "                    self.add_edge(v, d)\n",
    "\n",
    "    def add_vertex(self, v):\n",
    "        if v not in self.graph:\n",
    "            self.graph[v] = []\n",
    "\n",
    "    def add_edge(self, o, d):\n",
    "        self.add_vertex(o)\n",
    "        self.add_vertex(d)\n",
    "        if d not in self.graph[o]:\n",
    "            self.graph[o].append(d)\n",
    "\n",
    "    def print_graph(self):\n",
    "        for v in self.graph:\n",
    "            print(v, \"->\", self.graph[v])\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.get_nodes()), len(self.get_edges())\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return list(self.graph.keys())\n",
    "\n",
    "    def get_edges(self):\n",
    "        edges = []\n",
    "        for v in self.graph:\n",
    "            for d in self.graph[v]:\n",
    "                edges.append((v, d))\n",
    "        return edges\n",
    "\n",
    "    def get_successors(self, v):\n",
    "        return self.graph.get(v, [])\n",
    "\n",
    "    def get_predecessors(self, v):\n",
    "        return [u for u in self.graph if v in self.graph[u]]\n",
    "\n",
    "    def get_adjacents(self, v):\n",
    "        return list(set(self.get_successors(v)) | set(self.get_predecessors(v)))\n",
    "\n",
    "    def in_degree(self, v):\n",
    "        return len(self.get_predecessors(v))\n",
    "\n",
    "    def out_degree(self, v):\n",
    "        return len(self.get_successors(v))\n",
    "\n",
    "    def degree(self, v):\n",
    "        return len(self.get_adjacents(v))\n",
    "\n",
    "    def reachable_bfs(self, v):\n",
    "        queue = [v]\n",
    "        visited = set()\n",
    "        while queue:\n",
    "            node = queue.pop(0)\n",
    "            for neighbor in self.get_successors(node):\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    queue.append(neighbor)\n",
    "        return list(visited)\n",
    "\n",
    "    def reachable_dfs(self, v):\n",
    "        stack = [v]\n",
    "        visited = set()\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "            for neighbor in reversed(self.get_successors(node)):\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    stack.append(neighbor)\n",
    "        return list(visited)\n",
    "\n",
    "    def distance(self, s, d):\n",
    "        if s == d:\n",
    "            return 0\n",
    "        queue = [(s, 0)]\n",
    "        visited = set([s])\n",
    "        while queue:\n",
    "            node, dist = queue.pop(0)\n",
    "            for neighbor in self.get_successors(node):\n",
    "                if neighbor == d:\n",
    "                    return dist + 1\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    queue.append((neighbor, dist + 1))\n",
    "        return None\n",
    "\n",
    "    def shortest_path(self, s, d):\n",
    "        if s == d:\n",
    "            return [s]\n",
    "        queue = [(s, [])]\n",
    "        visited = set([s])\n",
    "        while queue:\n",
    "            node, path = queue.pop(0)\n",
    "            for neighbor in self.get_successors(node):\n",
    "                if neighbor == d:\n",
    "                    return path + [node, neighbor]\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    queue.append((neighbor, path + [node]))\n",
    "        return None\n",
    "\n",
    "    def node_has_cycle(self, v):\n",
    "        queue = [v]\n",
    "        visited = set([v])\n",
    "        while queue:\n",
    "            node = queue.pop(0)\n",
    "            for neighbor in self.get_successors(node):\n",
    "                if neighbor == v:\n",
    "                    return True\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    queue.append(neighbor)\n",
    "        return False\n",
    "\n",
    "    def has_cycle(self):\n",
    "        return any(self.node_has_cycle(v) for v in self.graph)\n",
    "\n",
    "    def visualize(self):\n",
    "        dot = graphviz.Digraph(comment='Graph', format='png')\n",
    "        for v in self.graph:\n",
    "            dot.node(v)\n",
    "        for v in self.graph:\n",
    "            for d in self.graph[v]:\n",
    "                dot.edge(v, d)\n",
    "        dot.render('output/unweighted_graph', view=True)\n",
    "\n",
    "\n",
    "class WeightedGraph(Graph):\n",
    "    def __init__(self, g=None):\n",
    "        self.graph = {}\n",
    "        if g:\n",
    "            for v, neighbors in g.items():\n",
    "                self.add_vertex(v)\n",
    "                for d, w in neighbors:\n",
    "                    self.add_edge(v, d, w)\n",
    "\n",
    "    def add_edge(self, o, d, w):\n",
    "        self.add_vertex(o)\n",
    "        self.add_vertex(d)\n",
    "        self.graph[o].append((d, w))\n",
    "\n",
    "    def get_edges(self):\n",
    "        edges = []\n",
    "        for v in self.graph:\n",
    "            for d, w in self.graph[v]:\n",
    "                edges.append((v, d, w))\n",
    "        return edges\n",
    "\n",
    "    def get_successors(self, v):\n",
    "        return [d for d, _ in self.graph.get(v, [])]\n",
    "\n",
    "    def dijkstra(self, start):\n",
    "        distances = {v: float('inf') for v in self.graph}\n",
    "        distances[start] = 0\n",
    "        heap = [(0, start)]\n",
    "        visited = set()\n",
    "\n",
    "        while heap:\n",
    "            dist_u, u = heapq.heappop(heap)\n",
    "            if u in visited:\n",
    "                continue\n",
    "            visited.add(u)\n",
    "            for v, weight in self.graph[u]:\n",
    "                alt = dist_u + weight\n",
    "                if alt < distances[v]:\n",
    "                    distances[v] = alt\n",
    "                    heapq.heappush(heap, (alt, v))\n",
    "        return distances\n",
    "\n",
    "    def visualize(self):\n",
    "        dot = graphviz.Digraph(comment='Weighted Graph', format='png')\n",
    "        for v in self.graph:\n",
    "            dot.node(v)\n",
    "        for v in self.graph:\n",
    "            for d, w in self.graph[v]:\n",
    "                dot.edge(v, d, label=str(w))\n",
    "        dot.render('output/weighted_graph', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e75400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unweighted Graph ===\n",
      "A -> ['B', 'C']\n",
      "B -> ['D']\n",
      "C -> ['D']\n",
      "D -> []\n",
      "Nodes: ['A', 'B', 'C', 'D']\n",
      "Edges: [('A', 'B'), ('A', 'C'), ('B', 'D'), ('C', 'D')]\n",
      "Size: (4, 4)\n",
      "Successors of A: ['B', 'C']\n",
      "Predecessors of B: ['A']\n",
      "Adjacents of C: ['A', 'D']\n",
      "Out-degree of B: 1\n",
      "In-degree of C: 1\n",
      "Degree of A: 2\n",
      "Shortest path from A to D: ['A', 'B', 'D']\n",
      "Distance from A to D: 2\n",
      "Reachable from A (BFS): ['B', 'C', 'D']\n",
      "Reachable from A (DFS): ['B', 'C', 'D']\n",
      "Graph has cycle: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Unweighted Graph ===\")\n",
    "g1 = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['D'],\n",
    "    'C': ['D'],\n",
    "    'D': []\n",
    "}\n",
    "\n",
    "G1 = Graph(g1)\n",
    "G1.print_graph()\n",
    "print(\"Nodes:\", G1.get_nodes())\n",
    "print(\"Edges:\", G1.get_edges())\n",
    "print(\"Size:\", G1.size())\n",
    "print(\"Successors of A:\", G1.get_successors(\"A\"))\n",
    "print(\"Predecessors of B:\", G1.get_predecessors(\"B\"))\n",
    "print(\"Adjacents of C:\", G1.get_adjacents(\"C\"))\n",
    "print(\"Out-degree of B:\", G1.out_degree(\"B\"))\n",
    "print(\"In-degree of C:\", G1.in_degree(\"C\"))\n",
    "print(\"Degree of A:\", G1.degree(\"A\"))\n",
    "print(\"Shortest path from A to D:\", G1.shortest_path('A', 'D'))\n",
    "print(\"Distance from A to D:\", G1.distance(\"A\", \"D\"))\n",
    "print(\"Reachable from A (BFS):\", G1.reachable_bfs('A'))\n",
    "print(\"Reachable from A (DFS):\", G1.reachable_dfs('A'))\n",
    "print(\"Graph has cycle:\", G1.has_cycle())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f9b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Weighted Graph ===\n",
      "A -> [('B', 1), ('C', 4)]\n",
      "B -> [('C', 2), ('D', 5)]\n",
      "C -> [('D', 1)]\n",
      "D -> []\n",
      "Nodes: ['A', 'B', 'C', 'D']\n",
      "Edges: [('A', 'B', 1), ('A', 'C', 4), ('B', 'C', 2), ('B', 'D', 5), ('C', 'D', 1)]\n",
      "Size: (4, 5)\n",
      "Successors of A: ['B', 'C']\n",
      "Predecessors of B: []\n",
      "Adjacents of C: ['D']\n",
      "Out-degree of B: 2\n",
      "In-degree of C: 0\n",
      "Degree of A: 2\n",
      "Dijkstra distances from A: {'A': 0, 'B': 1, 'C': 3, 'D': 4}\n",
      "Reachable from A (DFS): ['B', 'C', 'D']\n",
      "Graph has cycle: False\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Weighted Graph ===\")\n",
    "g2 = {\n",
    "    'A': [('B', 1), ('C', 4)],\n",
    "    'B': [('C', 2), ('D', 5)],\n",
    "    'C': [('D', 1)],\n",
    "    'D': []\n",
    "}\n",
    "\n",
    "G2 = WeightedGraph(g2)\n",
    "G2.print_graph()\n",
    "print(\"Nodes:\", G2.get_nodes())\n",
    "print(\"Edges:\", G2.get_edges())\n",
    "print(\"Size:\", G2.size())\n",
    "print(\"Successors of A:\", G2.get_successors(\"A\"))\n",
    "print(\"Predecessors of B:\", G2.get_predecessors(\"B\"))\n",
    "print(\"Adjacents of C:\", G2.get_adjacents(\"C\"))\n",
    "print(\"Out-degree of B:\", G2.out_degree(\"B\"))\n",
    "print(\"In-degree of C:\", G2.in_degree(\"C\"))\n",
    "print(\"Degree of A:\", G2.degree(\"A\"))\n",
    "print(\"Dijkstra distances from A:\", G2.dijkstra('A'))\n",
    "print(\"Reachable from A (DFS):\", G2.reachable_dfs('A'))\n",
    "print(\"Graph has cycle:\", G2.has_cycle())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbad18",
   "metadata": {},
   "source": [
    "# Redes Metabólicas\n",
    "\n",
    "##  Projeto de Alto Nível\n",
    "\n",
    "### Componentes Principais\n",
    "\n",
    "1. **Entrada de Dados (`ecoli.txt`)**\n",
    "   - Formato: uma reação por linha\n",
    "   - Exemplo: `R1: A + B => C + D`\n",
    "\n",
    "2. **Parser de Reações**\n",
    "   - Extrai dados estruturados de substratos e produtos\n",
    "   - Produz uma lista de dicionários:\n",
    "     ```python\n",
    "     {\n",
    "       \"id\": \"R1\",\n",
    "       \"substrates\": [\"A\", \"B\"],\n",
    "       \"products\": [\"C\", \"D\"]\n",
    "     }\n",
    "     ```\n",
    "\n",
    "3. **Construção do Grafo Metabólico**\n",
    "   - Usa a classe `MyGraph`\n",
    "   - Cada nó representa um metabolito\n",
    "   - Arestas ligam metabolitos que participam da mesma reação\n",
    "\n",
    "4. **Módulo de Centralidade (`CentralityAnalyzer`)**\n",
    "   - Calcula:\n",
    "     - Centralidade de grau (Degree)\n",
    "     - Centralidade de proximidade (Closeness)\n",
    "     - Centralidade de intermediação (Betweenness)\n",
    "\n",
    "5. **Módulo de Propagação de Metabolitos**\n",
    "   - Dado um conjunto inicial de metabolitos:\n",
    "     - Identifica reações ativas (todos os substratos disponíveis)\n",
    "     - Coleta produtos gerados\n",
    "     - Repete o processo iterativamente\n",
    "\n",
    "6. **Saída**\n",
    "   - Lista dos metabolitos mais centrais por métrica\n",
    "   - Metabolitos finais produzíveis a partir de um conjunto inicial\n",
    "\n",
    "---\n",
    "## Projeto de Baixo Nível\n",
    "\n",
    "### Funções Principais\n",
    "\n",
    "####  `parse_reactions(filepath)`\n",
    "- Lê `ecoli.txt` e transforma em dicionários de reação\n",
    "\n",
    "####  `build_metabolite_graph(reactions)`\n",
    "- Constrói um grafo a partir da coocorrência de metabolitos\n",
    "\n",
    "####  `CentralityAnalyzer`\n",
    "- Classe para cálculo das centralidades\n",
    "- Métodos:\n",
    "  - `degree_centrality()`\n",
    "  - `closeness_centrality()`\n",
    "  - `betweenness_centrality()`\n",
    "  - `top_nodes(centrality_dict, top_n)`\n",
    "\n",
    "####  `get_active_reactions(metabolites, reactions)`\n",
    "- Retorna reações cujos substratos estão disponíveis\n",
    "\n",
    "####  `get_produced_metabolites(active_reactions)`\n",
    "- Retorna os produtos das reações ativas\n",
    "\n",
    "####  `compute_final_metabolites(initial_metabs, reactions)`\n",
    "- Aplica a propagação metabólica iterativamente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163c3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_tuple_list(tl, val):\n",
    "    for (x, _) in tl:\n",
    "        if val == x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "class MN_Graph(Graph):\n",
    "    def reachable_with_dist(self, s):\n",
    "        res = []\n",
    "        l = [(s, 0)]\n",
    "        while l:\n",
    "            node, dist = l.pop(0)\n",
    "            if node != s:\n",
    "                res.append((node, dist))\n",
    "            for elem in self.get_successors(node):\n",
    "                if not is_in_tuple_list(l, elem) and not is_in_tuple_list(res, elem):\n",
    "                    l.append((elem, dist + 1))\n",
    "        return res\n",
    "\n",
    "    def mean_distances(self):\n",
    "        tot = 0\n",
    "        num_reachable = 0\n",
    "        for k in self.get_nodes():\n",
    "            distsk = self.reachable_with_dist(k)\n",
    "            for _, dist in distsk:\n",
    "                tot += dist\n",
    "            num_reachable += len(distsk)\n",
    "        meandist = float(tot) / num_reachable if num_reachable else 0\n",
    "        n = len(self.get_nodes())\n",
    "        density = float(num_reachable) / ((n - 1) * n) if n > 1 else 0\n",
    "        return meandist, density\n",
    "\n",
    "    def closeness_centrality(self, node):\n",
    "        dist = self.reachable_with_dist(node)\n",
    "        if len(dist) == 0:\n",
    "            return 0.0\n",
    "        s = sum(d[1] for d in dist)\n",
    "        return len(dist) / s\n",
    "\n",
    "    def highest_closeness(self, top=10):\n",
    "        cc = {k: self.closeness_centrality(k) for k in self.get_nodes()}\n",
    "        ord_cl = sorted(cc.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [x[0] for x in ord_cl[:top]]\n",
    "\n",
    "    def betweenness_centrality(self, node):\n",
    "        total_sp = 0\n",
    "        sps_with_node = 0\n",
    "        for s in self.get_nodes():\n",
    "            for t in self.get_nodes():\n",
    "                if s != t and s != node and t != node:\n",
    "                    sp = self.shortest_path(s, t)\n",
    "                    if sp:\n",
    "                        total_sp += 1\n",
    "                        if node in sp:\n",
    "                            sps_with_node += 1\n",
    "        return sps_with_node / total_sp if total_sp > 0 else 0.0\n",
    "\n",
    "    def clustering_coef(self, v):\n",
    "        adjs = self.get_adjacents(v)\n",
    "        if len(adjs) <= 1:\n",
    "            return 0.0\n",
    "        ligs = 0\n",
    "        for i in adjs:\n",
    "            for j in adjs:\n",
    "                if i != j and (j in self.get_successors(i) or i in self.get_successors(j)):\n",
    "                    ligs += 1\n",
    "        return float(ligs) / (len(adjs) * (len(adjs) - 1))\n",
    "\n",
    "    def all_clustering_coefs(self):\n",
    "        return {k: self.clustering_coef(k) for k in self.get_nodes()}\n",
    "\n",
    "    def mean_clustering_coef(self):\n",
    "        ccs = self.all_clustering_coefs()\n",
    "        return sum(ccs.values()) / float(len(ccs)) if ccs else 0.0\n",
    "\n",
    "    def mean_clustering_perdegree(self, deg_type=\"inout\"):\n",
    "        degs = self.all_degrees(deg_type)\n",
    "        ccs = self.all_clustering_coefs()\n",
    "        degs_k = {}\n",
    "        for k in degs:\n",
    "            degs_k.setdefault(degs[k], []).append(k)\n",
    "        ck = {}\n",
    "        for k in degs_k:\n",
    "            tot = sum(ccs[v] for v in degs_k[k])\n",
    "            ck[k] = tot / len(degs_k[k])\n",
    "        return ck\n",
    "\n",
    "\n",
    "class CentralityAnalyzer:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "\n",
    "    def degree_centrality(self):\n",
    "        return {node: len(self.graph.get_successors(node)) for node in self.graph.get_nodes()}\n",
    "\n",
    "    def closeness_centrality(self):\n",
    "        centrality = {}\n",
    "        for node in self.graph.get_nodes():\n",
    "            total_dist, reachable_count = self._bfs_total_distance_and_reach_count(node)\n",
    "            centrality[node] = (reachable_count / total_dist) if total_dist > 0 else 0.0\n",
    "        return centrality\n",
    "\n",
    "    def _bfs_total_distance_and_reach_count(self, start):\n",
    "        visited = set()\n",
    "        queue = deque([(start, 0)])\n",
    "        total = 0\n",
    "        reachable_count = 0\n",
    "\n",
    "        while queue:\n",
    "            node, dist = queue.popleft()\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                if node != start:\n",
    "                    total += dist\n",
    "                    reachable_count += 1\n",
    "                for neighbor in self.graph.get_successors(node):\n",
    "                    if neighbor not in visited:\n",
    "                        queue.append((neighbor, dist + 1))\n",
    "\n",
    "        return total, reachable_count\n",
    "\n",
    "\n",
    "    def betweenness_centrality(self):\n",
    "        centrality = dict.fromkeys(self.graph.get_nodes(), 0.0)\n",
    "        for s in self.graph.get_nodes():\n",
    "            stack = []\n",
    "            pred = {w: [] for w in self.graph.get_nodes()}\n",
    "            sigma = dict.fromkeys(self.graph.get_nodes(), 0)\n",
    "            dist = dict.fromkeys(self.graph.get_nodes(), -1)\n",
    "            sigma[s] = 1\n",
    "            dist[s] = 0\n",
    "            queue = deque([s])\n",
    "\n",
    "            while queue:\n",
    "                v = queue.popleft()\n",
    "                stack.append(v)\n",
    "                for w in self.graph.get_successors(v):\n",
    "                    if dist[w] < 0:\n",
    "                        dist[w] = dist[v] + 1\n",
    "                        queue.append(w)\n",
    "                    if dist[w] == dist[v] + 1:\n",
    "                        sigma[w] += sigma[v]\n",
    "                        pred[w].append(v)\n",
    "\n",
    "            delta = dict.fromkeys(self.graph.get_nodes(), 0)\n",
    "            while stack:\n",
    "                w = stack.pop()\n",
    "                for v in pred[w]:\n",
    "                    delta[v] += (sigma[v] / sigma[w]) * (1 + delta[w])\n",
    "                if w != s:\n",
    "                    centrality[w] += delta[w]\n",
    "        return centrality\n",
    "\n",
    "    def top_nodes(self, centrality_dict, top_n=5):\n",
    "        return heapq.nlargest(top_n, centrality_dict.items(), key=lambda x: x[1])\n",
    "\n",
    "# REACTION PARSER\n",
    "def parse_reactions(file_path):\n",
    "    \"\"\"Parses ecoli.txt into a list of reaction dicts\"\"\"\n",
    "    reactions = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if ':' not in line: continue\n",
    "            parts = re.split(r':\\s*', line.strip(), maxsplit=1)\n",
    "            if len(parts) != 2: continue\n",
    "            reaction_id, formula = parts\n",
    "            match = re.search(r\"^(.*?)\\s*(<=>|=>)\\s*(.*?)$\", formula)\n",
    "            if not match: continue\n",
    "            substrates = [m.strip() for m in match.group(1).split('+')]\n",
    "            products = [m.strip() for m in match.group(3).split('+')]\n",
    "            reactions.append({\n",
    "                'id': reaction_id,\n",
    "                'substrates': substrates,\n",
    "                'products': products\n",
    "            })\n",
    "    return reactions\n",
    "\n",
    "def build_metabolite_graph(reactions):\n",
    "    g = MN_Graph()\n",
    "    for r in reactions:\n",
    "        metabolites = r['substrates'] + r['products']\n",
    "        for i in range(len(metabolites)):\n",
    "            for j in range(i + 1, len(metabolites)):\n",
    "                g.add_edge(metabolites[i], metabolites[j])\n",
    "    return g\n",
    "\n",
    "# ASSESSMENT FUNCTIONS\n",
    "def get_active_reactions(metabolites_set, reactions):\n",
    "    return [r for r in reactions if all(sub in metabolites_set for sub in r['substrates'])]\n",
    "\n",
    "def get_produced_metabolites(active_reactions):\n",
    "    produced = set()\n",
    "    for r in active_reactions:\n",
    "        produced.update(r['products'])\n",
    "    return produced\n",
    "\n",
    "def compute_final_metabolites(initial_metabolites, reactions):\n",
    "    known_metabolites = set(initial_metabolites)\n",
    "    while True:\n",
    "        active = get_active_reactions(known_metabolites, reactions)\n",
    "        new = get_produced_metabolites(active)\n",
    "        if new.issubset(known_metabolites):\n",
    "            break\n",
    "        known_metabolites.update(new)\n",
    "    return known_metabolites\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458a0044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reactions parsed: 931\n",
      "\n",
      "--- Degree Centrality ---\n",
      "M_atp_c: 234\n",
      "M_h2o_c: 211\n",
      "M_h_c: 196\n",
      "M_pi_c: 132\n",
      "M_h_e: 98\n",
      "\n",
      "--- Closeness Centrality ---\n",
      "M_12ppd_DASH_S_e: 1.0000\n",
      "M_h2o_c: 0.5682\n",
      "M_h_c: 0.5672\n",
      "M_atp_c: 0.5637\n",
      "M_pi_c: 0.5192\n",
      "\n",
      "--- Betweenness Centrality ---\n",
      "M_h_c: 216934.6170\n",
      "M_h2o_c: 130880.9425\n",
      "M_atp_c: 73977.9868\n",
      "M_pi_c: 41413.1577\n",
      "M_h_e: 38528.6860\n",
      "\n",
      "--- Initial Metabolites ---\n",
      "['M_glc_DASH_D_c', 'M_h2o_c', 'M_nad_c', 'M_atp_c']\n",
      "\n",
      "--- Final Reachable Metabolites ---\n",
      "['M_13dpg_c', 'M_23ddhb_c', 'M_23dhb_c', 'M_23dhba_c', 'M_23dhmb_c', 'M_2dda7p_c', 'M_2ddg6p_c', 'M_2me4p_c', 'M_34hpp_c', 'M_3dhq_c', 'M_3dhsk_c', 'M_3mob_c', 'M_3psme_c', 'M_4hbz_c', 'M_4per_c', 'M_6pgc_c', 'M_6pgl_c', 'M_ade_c', 'M_adn_c', 'M_adp_c', 'M_adphep_DASH_DD_c', 'M_adphep_DASH_LD_c', 'M_alac_DASH_S_c', 'M_amp_c', 'M_ara5p_c', 'M_atp_c', 'M_camp_c', 'M_cbp_c', 'M_chor_c', 'M_co2_c', 'M_db4p_c', 'M_dha_c', 'M_dhap_c', 'M_dnad_c', 'M_dxyl5p_c', 'M_e4p_c', 'M_f6p_c', 'M_fdp_c', 'M_for_c', 'M_fprica_c', 'M_g3p_c', 'M_g6p_c', 'M_glc_DASH_D_c', 'M_gmhep17bp_c', 'M_gmhep1p_c', 'M_gmhep7p_c', 'M_h2_c', 'M_h2o_c', 'M_h_c', 'M_hco3_c', 'M_hxan_c', 'M_ichor_c', 'M_imp_c', 'M_ins_c', 'M_kdo8p_c', 'M_kdo_c', 'M_mthgxl_c', 'M_nac_c', 'M_nad_c', 'M_nadh_c', 'M_nadp_c', 'M_nadph_c', 'M_ncam_c', 'M_nh4_c', 'M_nicrnt_c', 'M_nmn_c', 'M_oaa_c', 'M_ohpb_c', 'M_pep_c', 'M_phpyr_c', 'M_pi_c', 'M_pphn_c', 'M_ppi_c', 'M_prbamp_c', 'M_prbatp_c', 'M_prfp_c', 'M_prlp_c', 'M_prpp_c', 'M_pyr_c', 'M_r1p_c', 'M_r5p_c', 'M_ru5p_DASH_D_c', 'M_s7p_c', 'M_skm5p_c', 'M_skm_c', 'M_xan_c', 'M_xmp_c', 'M_xtsn_c', 'M_xu5p_DASH_D_c']\n"
     ]
    }
   ],
   "source": [
    "file_path = \"ecoli.txt\"\n",
    "reactions = parse_reactions(file_path)\n",
    "\n",
    "print(\" Reactions parsed:\", len(reactions))\n",
    "\n",
    "# Centrality Analysis\n",
    "g = build_metabolite_graph(reactions)\n",
    "analyzer = CentralityAnalyzer(g)\n",
    "\n",
    "print(\"\\n--- Degree Centrality ---\")\n",
    "for node, val in analyzer.top_nodes(analyzer.degree_centrality()):\n",
    "    print(f\"{node}: {val}\")\n",
    "\n",
    "print(\"\\n--- Closeness Centrality ---\")\n",
    "for node, val in analyzer.top_nodes(analyzer.closeness_centrality()):\n",
    "    print(f\"{node}: {val:.4f}\")\n",
    "\n",
    "print(\"\\n--- Betweenness Centrality ---\")\n",
    "for node, val in analyzer.top_nodes(analyzer.betweenness_centrality()):\n",
    "    print(f\"{node}: {val:.4f}\")\n",
    "\n",
    "#  Metabolite Propagation \n",
    "initial_metabs = [\"M_glc_DASH_D_c\", \"M_h2o_c\", \"M_nad_c\", \"M_atp_c\"]\n",
    "final_metabs = compute_final_metabolites(initial_metabs, reactions)\n",
    "\n",
    "print(\"\\n--- Initial Metabolites ---\")\n",
    "print(initial_metabs)\n",
    "\n",
    "print(\"\\n--- Final Reachable Metabolites ---\")\n",
    "print(sorted(final_metabs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31adcaf",
   "metadata": {},
   "source": [
    "## Genome Assembly\n",
    "\n",
    "### High-Level Description (Conceptual)\n",
    "\n",
    "**Goal**: Reconstruct the original DNA sequence from a list of overlapping fragments (k-mers).\n",
    "\n",
    "**Approach**:\n",
    "\n",
    "1. **De Bruijn Graph**:\n",
    "\n",
    "   * Represent k-mers as edges.\n",
    "   * Nodes are (k-1)-mers (prefixes/suffixes).\n",
    "   * Find an **Eulerian path**: a path that visits every edge exactly once.\n",
    "   * Rebuild the sequence by following this path.\n",
    "\n",
    "2. **Overlap Graph**:\n",
    "\n",
    "   * Represent k-mers as nodes.\n",
    "   * Add an edge from node A to node B if the suffix of A matches the prefix of B (length k-1).\n",
    "   * Find a **Hamiltonian path**: a path that visits every node exactly once.\n",
    "   * Reconstruct the sequence by joining overlapping fragments along the path.\n",
    "\n",
    "---\n",
    "\n",
    "###  Low-Level Description (Implementation)\n",
    "\n",
    "**De Bruijn Algorithm**:\n",
    "\n",
    "* For each k-mer, add an edge from `prefix(k-mer)` to `suffix(k-mer)`.\n",
    "* Ensure the graph is *nearly balanced* (1 start, 1 end node).\n",
    "* Add a temporary edge from end to start.\n",
    "* Use **Hierholzer’s algorithm** to find an Eulerian cycle.\n",
    "* Remove the temporary edge to get the Eulerian path.\n",
    "* Reconstruct the sequence by concatenating characters from each node.\n",
    "\n",
    "**Overlap Graph Algorithm**:\n",
    "\n",
    "* Label each fragment uniquely (e.g., `\"ATG-1\"`).\n",
    "* For every pair of fragments, add an edge if `suffix(A) == prefix(B)`.\n",
    "* Use **backtracking** to search for a Hamiltonian path.\n",
    "* Rebuild the sequence using the first full fragment and last characters from the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb01237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix(seq): return seq[:-1]\n",
    "def suffix(seq): return seq[1:]\n",
    "\n",
    "class DeBruijnGraph(Graph):\n",
    "    def __init__(self, frags):\n",
    "        super().__init__()\n",
    "        # Add edges where each k-mer contributes an edge from its prefix to its suffix\n",
    "        for seq in frags:\n",
    "            self.add_edge(prefix(seq), suffix(seq))\n",
    "\n",
    "    def check_nearly_balanced_graph(self):\n",
    "        # Identify if the graph is nearly balanced:\n",
    "        # One node with out-degree = in-degree + 1 (start)\n",
    "        # One node with in-degree = out-degree + 1 (end)\n",
    "        res = None, None  # (start, end)\n",
    "        for n in self.graph:\n",
    "            indeg = self.in_degree(n)\n",
    "            outdeg = self.out_degree(n)\n",
    "            if indeg - outdeg == 1:\n",
    "                res = res[0], n  # candidate to be end node\n",
    "            elif outdeg - indeg == 1:\n",
    "                res = n, res[1]  # candidate to be start node\n",
    "            elif indeg != outdeg:\n",
    "                return None, None  # not balanced or nearly balanced\n",
    "        return res\n",
    "\n",
    "    def eulerian_path(self):\n",
    "        # Find a Eulerian path using Hierholzer's algorithm\n",
    "        start, end = self.check_nearly_balanced_graph()\n",
    "        if not start or not end:\n",
    "            return None\n",
    "\n",
    "        # Add a temporary edge to make the graph Eulerian\n",
    "        self.add_edge(end, start)\n",
    "\n",
    "        path = []\n",
    "        stack = [start]\n",
    "        # Copy of graph edges to allow mutation during traversal\n",
    "        edges = {u: list(vs) for u, vs in self.graph.items()}\n",
    "\n",
    "        while stack:\n",
    "            u = stack[-1]\n",
    "            if edges.get(u):\n",
    "                stack.append(edges[u].pop())\n",
    "            else:\n",
    "                path.append(stack.pop())\n",
    "\n",
    "        path.reverse()\n",
    "\n",
    "        # Remove the temporary edge to recover the original path\n",
    "        for i in range(len(path) - 1):\n",
    "            if path[i] == end and path[i + 1] == start:\n",
    "                return path[i + 1:] + path[1:i + 1]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def seq_from_path(self, path):\n",
    "        # Reconstruct the original sequence from a Eulerian path\n",
    "        if not path:\n",
    "            return None\n",
    "        return path[0] + ''.join(n[-1] for n in path[1:])\n",
    "\n",
    "class OverlapGraph(Graph):\n",
    "    def __init__(self, frags):\n",
    "        super().__init__()\n",
    "\n",
    "        # Add unique suffix to each fragment to handle duplicates\n",
    "        self.frags = [f\"{f}-{i}\" for i, f in enumerate(frags, 1)]\n",
    "\n",
    "        # Add all vertices to the graph\n",
    "        for f in self.frags:\n",
    "            self.add_vertex(f)\n",
    "\n",
    "        # Add edges based on overlap: suffix of f1 matches prefix of f2\n",
    "        for f1 in self.frags:\n",
    "            s1 = suffix(f1.split('-')[0])  # suffix of the sequence\n",
    "            for f2 in self.frags:\n",
    "                if prefix(f2.split('-')[0]) == s1:\n",
    "                    self.add_edge(f1, f2)\n",
    "\n",
    "    def search_hamiltonian_path(self):\n",
    "        # Try to find a Hamiltonian path using backtracking\n",
    "        def bt(path):\n",
    "            if len(path) == len(self.graph):\n",
    "                return path\n",
    "            for neighbor in self.graph[path[-1]]:\n",
    "                if neighbor not in path:\n",
    "                    res = bt(path + [neighbor])\n",
    "                    if res:\n",
    "                        return res\n",
    "            return None\n",
    "\n",
    "        # Attempt to start from every vertex\n",
    "        for start in self.graph:\n",
    "            res = bt([start])\n",
    "            if res:\n",
    "                return res\n",
    "        return None\n",
    "\n",
    "    def get_seq(self, node):\n",
    "        # Extract the original sequence from node label (e.g., 'ATG-3' -> 'ATG')\n",
    "        return node.split('-')[0]\n",
    "\n",
    "    def seq_from_path(self, path):\n",
    "        # Reconstruct sequence from Hamiltonian path\n",
    "        if not path:\n",
    "            return None\n",
    "        return self.get_seq(path[0]) + ''.join(self.get_seq(n)[-1] for n in path[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a690c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sequence: ATGCAATGGTCTG\n",
      "k-mers: ['AAT', 'ATG', 'ATG', 'CAA', 'CTG', 'GCA', 'GGT', 'GTC', 'TCT', 'TGC', 'TGG']\n",
      "\n",
      "--- De Bruijn ---\n",
      "AA -> ['AT']\n",
      "AT -> ['TG']\n",
      "TG -> ['GC', 'GG']\n",
      "CA -> ['AA']\n",
      "CT -> ['TG']\n",
      "GC -> ['CA']\n",
      "GG -> ['GT']\n",
      "GT -> ['TC']\n",
      "TC -> ['CT']\n",
      "Eulerian path not found.\n",
      "\n",
      "--- Overlap with repetitions ---\n",
      "AAT-1 -> ['ATG-2', 'ATG-3']\n",
      "ATG-2 -> ['TGC-10', 'TGG-11']\n",
      "ATG-3 -> ['TGC-10', 'TGG-11']\n",
      "CAA-4 -> ['AAT-1']\n",
      "CTG-5 -> ['TGC-10', 'TGG-11']\n",
      "GCA-6 -> ['CAA-4']\n",
      "GGT-7 -> ['GTC-8']\n",
      "GTC-8 -> ['TCT-9']\n",
      "TCT-9 -> ['CTG-5']\n",
      "TGC-10 -> ['GCA-6']\n",
      "TGG-11 -> ['GGT-7']\n",
      "Hamiltonian path found: ['ATG-2', 'TGC-10', 'GCA-6', 'CAA-4', 'AAT-1', 'ATG-3', 'TGG-11', 'GGT-7', 'GTC-8', 'TCT-9', 'CTG-5']\n",
      "Reconstructed sequence: ATGCAATGGTCTG\n"
     ]
    }
   ],
   "source": [
    "def composition(k, seq):\n",
    "    return sorted([seq[i:i+k] for i in range(len(seq)-k+1)])\n",
    "\n",
    "def run_all(seq, k):\n",
    "    print(\"Original sequence:\", seq)\n",
    "    frags = composition(k, seq)\n",
    "    print(\"k-mers:\", frags)\n",
    "\n",
    "    # De Bruijn Graph Method\n",
    "    print(\"\\n--- De Bruijn ---\")\n",
    "    dbg = DeBruijnGraph(frags)\n",
    "    dbg.print_graph()\n",
    "    path = dbg.eulerian_path()\n",
    "    if path:\n",
    "        print(\"Eulerian path found:\", path)\n",
    "        print(\"Reconstructed sequence:\", dbg.seq_from_path(path))\n",
    "    else:\n",
    "        print(\"Eulerian path not found.\")\n",
    "\n",
    "    # Overlap Graph Method with repetitions\n",
    "    print(\"\\n--- Overlap with repetitions ---\")\n",
    "    og = OverlapGraph(frags)\n",
    "    og.print_graph()\n",
    "    path = og.search_hamiltonian_path()\n",
    "    if path:\n",
    "        print(\"Hamiltonian path found:\", path)\n",
    "        print(\"Reconstructed sequence:\", og.seq_from_path(path))\n",
    "    else:\n",
    "        print(\"Hamiltonian path not found.\")\n",
    "\n",
    "run_all('ATGCAATGGTCTG', 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
